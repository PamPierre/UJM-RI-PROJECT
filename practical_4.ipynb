{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9fbc08f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@Djibril ===> With stopword && With stemmer\n",
    "@Omeima ===> With stopword && No stemmer\n",
    "@Doua ===> No stopword && With stemmer\n",
    "@Moh ===> No stopword && No stemmer\n",
    "\"\"\"\n",
    "from os import *\n",
    "import practice2\n",
    "import re\n",
    "import practice3\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "from stop_words import get_stop_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8491d2d",
   "metadata": {},
   "source": [
    "## sigles:\n",
    "- wf = Weiting function (ltn,ltc,bm25)\n",
    "- pl = Posting list{'term':[('docno','frequence')....]} \n",
    "- lt = Liste terme('Docno': '[list of terme]')\n",
    "- stat = statistiques\n",
    "- sw = Stopwords\n",
    "- st = stemmer\n",
    "- q = query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "32da452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_directory():\n",
    "    if not path.exists(\"assets\"):\n",
    "        mkdir('assets')\n",
    "    if not path.exists(\"assets/runs_result/\"):\n",
    "        mkdir(\"assets/runs_result/\")\n",
    "# text_mining(fileName,use_stem=bool(),use_stopword=bool())\n",
    "def create_pl_lt_stat_files(corpus_filename, use_stem,use_stopword):\n",
    "    posting_list, list_terms,indexing_time = practice2.text_mining(filename,\n",
    "                                                                    use_stem,\n",
    "                                                                   use_stopword)\n",
    "    if use_stopword:\n",
    "        sw=''\n",
    "    else:\n",
    "        sw = 'no'\n",
    "    if use_stem:\n",
    "        st=''\n",
    "    else:\n",
    "        st = 'no'\n",
    "    \n",
    "    # Create the txt file to save the posting_list and liste_terme values\n",
    "    create_write_file(posting_list,sw,st,True)\n",
    "    create_write_file(list_terms,sw,st,False)\n",
    "    \n",
    "    #Get the statistique\n",
    "    stat = practice2.get_statistics(posting_list, list_terms)\n",
    "    return posting_list,list_terms,stat,indexing_time\n",
    "    \n",
    "def create_write_file(var_l,sw,st,pl):\n",
    "    filename = open(build_filename(sw,st,pl),\"w\")\n",
    "    for val in var_l.items():\n",
    "        filename.write(str(val)+ \"\\n\")\n",
    "    filename.close()\n",
    "    \n",
    "def build_filename(sw,st,pl):\n",
    "    type_name =\"posting_list_\"\n",
    "    if not pl:\n",
    "        type_name = \"list_termes_\"\n",
    "    filedirectory = \"assets/\"\n",
    "    filename = str(filedirectory+type_name+'{}stopword_{}stem.txt'.format(sw,st))\n",
    "    print(str(filename)+' Created !!')\n",
    "    return filename\n",
    "\n",
    "# Get posting liste and list term from file\n",
    "def get_pl_lt_from_file(use_stem,use_stopword):\n",
    "    start = time.time()\n",
    "    \n",
    "    if use_stopword:\n",
    "        sw=''\n",
    "    else:\n",
    "        sw = 'no'\n",
    "    if use_stem:\n",
    "        st=''\n",
    "    else:\n",
    "        st = 'no'\n",
    "    pl_filename = build_filename(sw,st,True)\n",
    "    lt_filename = build_filename(sw,st,False)\n",
    "    \n",
    "    posting_list = get_pl_dict_from_file(str(pl_filename),True)\n",
    "    list_terms = get_pl_dict_from_file(str(lt_filename),False)\n",
    "    stat = practice2.get_statistics(posting_list, list_terms)\n",
    "    \n",
    "    \n",
    "    return posting_list,list_terms,stat,(time.time()-start)\n",
    "\n",
    "# Build a dict(pl or lt) from scratch with a file\n",
    "def get_pl_dict_from_file(filename,pl = bool()):\n",
    "    filecontent = practice2.preprocesFile(str(filename))\n",
    "    dict_file = {}\n",
    "    content = []\n",
    "    i=0\n",
    "    for line in filecontent.split('\\n'):\n",
    "        for k in line.split(', ',1):\n",
    "            i+=1\n",
    "            if i%2==0:\n",
    "                \n",
    "                if pl:\n",
    "                    content = rebuild_df(k)\n",
    "                else:\n",
    "                    content = re.sub(r'[^\\w\\s]', '', str(k)).split()\n",
    "                # rsplit(')',1 )Remplace le dernier ) par rien\n",
    "                dict_file[word] = content\n",
    "            word = k.replace(\"(\",'').replace('\\'','')\n",
    "    return dict_file\n",
    "\n",
    "def rebuild_df(content):\n",
    "    doc = re.sub(r'[^\\w\\s]', '', str(content))\n",
    "    j = 0\n",
    "    df = []\n",
    "    for v in doc.split():\n",
    "        j+=1\n",
    "        if j%2==0:\n",
    "            df.append((docn,int(v)))\n",
    "        docn = v\n",
    "    return df\n",
    "\n",
    "# build run ict for the weiting function\n",
    "\n",
    "def score(query_list,rsv_wf):\n",
    "    score = []\n",
    "    for query in query_list:\n",
    "        query  = query.split(' ',1)\n",
    "        score.append(result_query(query[0],practice3.rsv_score(query[1],rsv_wf),team_name))\n",
    "    return score,(len(score) * len(score[0]))\n",
    "\n",
    "# For all weigting function\n",
    "def all_score_wf(query_list, ltn,ltc,bm25):\n",
    "    start = time.time()\n",
    "    score_ltn,l_ltn = score(query,ltn)\n",
    "    print(\"Ltn time : \",time.time() -start)\n",
    "    start = time.time()\n",
    "    score_ltc,l_ltc = score(query,ltc)\n",
    "    print(\"Ltc time : \",time.time() -start)\n",
    "    start = time.time()\n",
    "    score_bm25,l_bm25 = score(query,bm25)\n",
    "    print(\"Bm25 time : \",time.time() -start)\n",
    "    len_all_score = sum([l_ltn,l_ltc,l_bm25])\n",
    "    \n",
    "    return score_ltn,score_ltc,score_bm25,len_all_score\n",
    "\n",
    "# 2009011 Q0 15343730 1 0.011317152113888167 Mathias /article[1]\n",
    "def result_query(num_query, rsv_result,team_name):\n",
    "    score = reverse_score(rsv_result)\n",
    "    x = score\n",
    "    if len(x)>1500:\n",
    "        x = x[:1500]\n",
    "    rsv_r = [(num_query,\n",
    "              'Q0', x[i][0],i+1,\n",
    "              round(x[i][1],5), team_name, \n",
    "              '/article[1]') for i in range(len(x))]\n",
    "    return rsv_r\n",
    "\n",
    "def reverse_score(score_result):\n",
    "    score = sorted(score_result, reverse=True)\n",
    "    score = [(doc, result) for result, doc in score]\n",
    "    return score\n",
    "\n",
    "# wf_index is [0,1,2]==['ltn','ltc','bm25']\n",
    "def create_run_file(run_id,wf_index,use_stem,use_stopword,k,b):\n",
    "    run_directory = \"assets/runs_result/\"\n",
    "    run_id+=1\n",
    "    team_name = \"DjibrilMohamedOmaimaDouae\"\n",
    "    stem = ['nostem', 'porter', 'lovins', 'paice']\n",
    "    wf = ['ltn', 'ltc', 'bm25']\n",
    "    st = stem[0]\n",
    "    sw = 'nostop'\n",
    "    stopwords = get_stop_words('english')\n",
    "    len_stop = ''\n",
    "    if(use_stopword):\n",
    "        sw = 'stop'\n",
    "        len_stop = str(len(stopwords))\n",
    "    if use_stem:\n",
    "        st = stem[1]\n",
    "                #name_Runid_wf_Granularity_use_Parameters.tx\n",
    "    run_file_name = '{}_{}_{}_element_sec_p_{}{}_{}'.format(team_name,run_id,\n",
    "                                                          wf[wf_index],sw,\n",
    "                                                          len_stop,st)\n",
    "    #Cas du bm25\n",
    "    if (wf_index == 2):\n",
    "        run_file_name = str(run_file_name+'_k{}_b{}'.format(k,b))\n",
    "        \n",
    "    run_file_path = str(run_directory+run_file_name+'.txt')\n",
    "    return open(run_file_path,\"w\"),run_id\n",
    "\n",
    "# index is [0,1,2]==['ltn','ltc','bm25']\n",
    "def build_run_file(run_id,wf_score,index,use_stem,use_stopword,k,b):\n",
    "    start = time.time()\n",
    "    if index!=2:\n",
    "        k=0.0\n",
    "        b=0.0\n",
    "    run_file_name,run_id = create_run_file(run_id,index,use_stem,use_stopword,k,b)\n",
    "    for score in wf_score:\n",
    "        for i in range(len(score)):\n",
    "            run_score = str(score[i]).replace(',','').replace(\"'\",'').replace('(','').replace(')','')\n",
    "            run_file_name.write(run_score + \"\\n\")  \n",
    "    run_file_name.close()\n",
    "    \n",
    "    print(\"Execution time for the run {} is {}\".format(run_id,time.time()-start))\n",
    "    return run_id\n",
    "# uniquement pour le bm25tuning for a random value:\n",
    "def bm25_tuning_random(run_id,number_run,score_bm25,use_stem,use_stopword):\n",
    "    for i in range(number_run):\n",
    "        k = random.uniform(1, 2)\n",
    "        b = random.uniform(0.1, 1)\n",
    "        run_id = build_run_file(run_id, score_bm25,2,use_stem,use_stopword,k,b)\n",
    "    print(\"Run number is {}\".format(run_id))\n",
    "    \n",
    "def bm25_tuning(run_id,score_bm25,use_stem,use_stopword):\n",
    "    k = 1.2\n",
    "    b = 0.0\n",
    "    for i in range(11):\n",
    "        run_id = build_run_file(run_id, score_bm25,2,use_stem,use_stopword,k,b)\n",
    "        b+=0.1\n",
    "    k = 0.0\n",
    "    b = 0.75\n",
    "    for i in range(21):\n",
    "        run_id = build_run_file(run_id, score_bm25,2,use_stem,use_stopword,k,b)\n",
    "        k+=0.2\n",
    "    print(\"Run number is {}\".format(run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bfd837f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the corpus file\n",
    "directory = \"Practice_03_data/\"\n",
    "list_data = practice2.list_file_data(directory)\n",
    "filename = str(directory+list_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "23934ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the query file\n",
    "directory = \"Practice_04_data/topics_M2DSC_7Q.txt\"\n",
    "#list_data_q = practice2.list_file_data(directory)\n",
    "filename_q = directory #str(directory+list_data_q[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a1ec6258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell to initialise global variable\n",
    "team_name = \"DjibrilMohamedOmaimaDouae\"\n",
    "assets = \"assets/\"\n",
    "k = 1.2\n",
    "b = 0.75\n",
    "use_stem = True\n",
    "use_stopword = True\n",
    "run_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f8f859ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = practice2.preprocesFile(filename_q)\n",
    "query = query_list.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ec237580",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11417ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assets/posting_list_stopword_stem.txt Created !!\n",
      "assets/list_termes_stopword_stem.txt Created !!\n"
     ]
    }
   ],
   "source": [
    "# Exemple cell for only test\n",
    "\n",
    "# Test 1 create a pl and lt without stopword and without stemmer\n",
    "# pl,lt,stat,id_time = create_pl_lt_stat_files(filename, use_stem,use_stopword) # 4 bugs fixed\n",
    "\n",
    "# Test 2 rebuild indexing listes from files\n",
    "pl,lt,stat,id_time = get_pl_lt_from_file( use_stem,use_stopword) # 3 bugs fixed also indexing time too high:64.09\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c04926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell to  print variable\n",
    "id_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "431eb299",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#filecontent = practice2.preprocesFile(str(assets+\"list_termes_stopword_stem.text\"))\n",
    "#content = filecontent.split('\\n')[0].split(', ',1)[1]\n",
    "#re.sub(r'[^\\w\\s]', '', str(content)).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9e7f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ad41af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6e673c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f56d9c1c",
   "metadata": {},
   "source": [
    "Temps d'execution de recuperation de chaque donné\n",
    "- T = True ----  F = false\n",
    "- X1X2--> X1 = used stopword ---- X2 used stemmer\n",
    "    * TT - 17.62372136116028\n",
    "    * FT - 11.378056526184082\n",
    "    * TF - 8.721906900405884\n",
    "    * FF - 11.420051336288452"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26ba83c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9354889e",
   "metadata": {},
   "source": [
    "## Compute weiting function\n",
    "*Don't forget to import practice3.py !!!*\n",
    "_each wf has a index number to create easily the file name_ Dont forget the index number <== A revoir car pas tres pratique\n",
    "* ltn = practice3.smart_ltn(pl,stat['n_doc'], stat['colec_freq'])\n",
    "* ltc = practice3.smart_ltc(ltn) _if ltn is not define compute it before compute the ltc_\n",
    "* bm25 = practice3.bm25(pl,stat,k,b)\n",
    "* All function : ltn,ltc,bm25 = practice3.weinting_function(posting_list, stat,1.2,0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "173c52a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell for wf funtions\n",
    "# Test 1 compute all wf RSV\n",
    "#ltn,ltc,bm25 = practice3.weinting_function(pl, stat,1.2,0.75) # no bugs\n",
    "# Test 2 compute all wf score\n",
    "# score_ltn,score_ltc,score_bm25,len_all_score = all_score_wf(query, ltn,ltc,bm25) #6 bugs fixed\n",
    "\n",
    "# Test 3 build run file\n",
    "# run_id = build_run_file(run_id, score_ltc,1,use_stem,use_stopword,k,b) # 1\n",
    "# run_id = build_run_file(run_id, score_bm25,2,use_stem,use_stopword,k,b)\n",
    "# For tuning\n",
    "# bm25_tuning(run_id,40,score_bm25,use_stem,use_stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5001423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_ltn,score_ltc,score_bm25,len_all_score = all_score_wf(query, ltn,ltc,bm25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d646d167",
   "metadata": {},
   "source": [
    "Next step, take all the case of posting list(with stopword, nostopword, stem,nostem) and share task to everyone to do one case done§!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78be0789",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = bm25_tuning(run_id,score_bm25,use_stem,use_stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c56040d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
