{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3627e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import practice2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4426b601",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"Practice_03_data/\"\n",
    "list_data = practice2.list_file_data(directory)\n",
    "filename = str(directory+list_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7402f5b7",
   "metadata": {},
   "source": [
    "## Exercise 2: Collection Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78fa9c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_1, lt_1 = practice2.text_mining(filename,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9c55aa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stat_1 = practice2.get_statistics(pl_1, lt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb21fa71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f9d2e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = pd.DataFrame(stat_1['df'],columns=['Document numbers', 'DL'])\n",
    "tl = pd.DataFrame(stat_1['tl'],columns=['Terms', 'tl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80bf0b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_freq_l = list()\n",
    "for k,v in stat_1['colec_freq'].items():\n",
    "    c_freq_l.append((k,v[0][0],v[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "571aefc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_freq = pd.DataFrame(c_freq_l,columns=['Terms', 'freq','Df'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d322d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_red = tl[:100]\n",
    "c_f_red = c_freq[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afbf20a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('statistique.xlsx')\n",
    "dl.to_excel(writer,'Document lenght')\n",
    "tl_red.to_excel(writer,'Terms lenght')\n",
    "c_f_red.to_excel(writer,'Collection frequency terms')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fceffdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6797834e",
   "metadata": {},
   "source": [
    "## Exercise 3: Collection Statistics using stop-words and stemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff71a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_2, lt_2 = practice2.text_mining(filename,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b820fd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stat_2 = practice2.get_statistics(pl_2,lt_2)\n",
    "#pl_2 = take(100, pl_2.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6aed3aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = pd.DataFrame(stat_2['df'],columns=['Document numbers', 'DL'])\n",
    "tl = pd.DataFrame(stat_2['tl'],columns=['Terms', 'tl'])\n",
    "\n",
    "c_freq_l = list()\n",
    "i=0\n",
    "for k,v in stat_2['colec_freq'].items():\n",
    "    i+=1\n",
    "    if i==200: break\n",
    "    c_freq_l.append((k,v[0][0],v[0][1]))\n",
    "\n",
    "c_freq = pd.DataFrame(c_freq_l,columns=['Terms', 'freq','Df'])\n",
    "\n",
    "tl_red = tl[:100]\n",
    "c_f_red = c_freq[:150]\n",
    "\n",
    "writer = pd.ExcelWriter('statistique_stopword_stemming.xlsx')\n",
    "dl.to_excel(writer,'Document lenght')\n",
    "tl_red.to_excel(writer,'Terms lenght')\n",
    "c_f_red.to_excel(writer,'Collection frequency terms')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676a4e47",
   "metadata": {},
   "source": [
    "## Exercise 4: SMART ltn weighting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36a93eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_ltn(posting_list,n):\n",
    "    df = 0\n",
    "    #(1+LOG(tf))*LOG(n/df)\n",
    "    #tf is the frequence of term on a document\n",
    "    #df number of document where the term appear\n",
    "    ltn_value = {} # key doc number, value (terme, ltn)\n",
    "    for term, value in posting_list.items():\n",
    "        df =len(value) #\n",
    "        for v in value:\n",
    "            tf = v[1]\n",
    "            if df == 0:\n",
    "                ltn=0\n",
    "            else:\n",
    "                ltn = (1+math.log(tf))*math.log(n/df)\n",
    "            ltn_value.setdefault(v[0],[]).append((term,ltn))\n",
    "    return ltn_value\n",
    "\n",
    "s_ltn = smart_ltn(pl_2, stat_2['n_doc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434a75f1",
   "metadata": {},
   "source": [
    "## Exercise 5: Ranked Retrieval (ltn weighting) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecd7f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"web ranking scoring algorithm\"\n",
    "# Doc = score(sum(ltn(term)))\n",
    "def rsv_score(query,ltn):\n",
    "    rsv_doc = {}\n",
    "    for term in query.split():\n",
    "        for doc, values in ltn.items():\n",
    "            for v in values:\n",
    "                if term in v[0]:\n",
    "                    rsv_doc.setdefault(doc,[]).append(v[1]) \n",
    "                else: continue\n",
    "    rsv = [(sum(ltn_list),doc) for doc,ltn_list in rsv_doc.items()]\n",
    "    return rsv\n",
    "\n",
    "rsv = rsv_score(query,s_ltn)\n",
    "#rsv = practice2.scoring_doc(practice2.clean(query, True), posting_list, list_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "929d0e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4698944', 449.68585544312054),\n",
       " ('444250', 398.936024569417),\n",
       " ('33139', 293.95143902325106),\n",
       " ('9071052', 264.3803997107955),\n",
       " ('18568', 250.0145026585329),\n",
       " ('33120', 232.3370616875538),\n",
       " ('7672374', 225.9156690940626),\n",
       " ('15308316', 223.64523200641196),\n",
       " ('448834', 214.41567654730872),\n",
       " ('195870', 210.27835231866374)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = sorted(rsv, reverse=True) # To get the score descending\n",
    "score = [(doc, ltn) for ltn, doc in score]\n",
    "score[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5bc05c",
   "metadata": {},
   "source": [
    "## Exercise 6: SMART ltc weighting \n",
    " - Compute a weighted index based on SMART ltc weighting function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ef821ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_ltc(smart_ltn):\n",
    "    # ltn = doc:(term, ltn)\n",
    "    #  (ltn_term/sqrt(sum(each pow(ltn_term,2))on a document))\n",
    "    ltc_value = {}\n",
    "    for doc, value in smart_ltn.items():\n",
    "        pow_ltn_term = [pow(v[1],2) for v in value]\n",
    "        normalize = math.sqrt(sum(pow_ltn_term))\n",
    "        for v in value:\n",
    "            ltc_value.setdefault(doc,[]).append((v[0],v[1]/normalize))\n",
    "    return ltc_value\n",
    "\n",
    "s_ltc = smart_ltc(s_ltn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86627b3",
   "metadata": {},
   "source": [
    "## Exercise 7: Ranked Retrieval (ltc weighting) \n",
    "Compute the score of each document for the query  « web ranking scoring algorithm », using the index based \n",
    "on SMART ltc weighting function. Print the list of the ten most relevant documents, and their relevance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc90a56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('9071052', 2.4316182923266667),\n",
       " ('7672374', 2.191647713817547),\n",
       " ('4698944', 1.6059559755167894),\n",
       " ('195870', 1.5909263855644207),\n",
       " ('3103995', 1.5674681087184965),\n",
       " ('7576424', 1.5473266829983465),\n",
       " ('15686791', 1.514233947049167),\n",
       " ('6270108', 1.4911388528838958),\n",
       " ('6497220', 1.4832313759131743),\n",
       " ('33139', 1.4630890122775557)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsv_c = rsv_score(query,s_ltc)\n",
    "score_c = sorted(rsv_c, reverse=True)\n",
    "score_c = [(doc, ltc) for ltc, doc in score_c]\n",
    "score_c[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8963f7",
   "metadata": {},
   "source": [
    "## Exercise 8: BM25 weighting \n",
    "Compute a weighted index based on BM25 weighting function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb51d430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_part(posting_list,dl):\n",
    "    #(tf*(k+1))/(k*((1-b)+b*(dl/avdl))+tf)\n",
    "    #[  1     ]             [   2   ]\n",
    "    #              [      3         ]\n",
    "    #            [         4            ]   \n",
    "    k = 1.2\n",
    "    b = 0.75\n",
    "    dl_ = [dl_ for _, dl_ in dl]\n",
    "    doc_len = 0\n",
    "    avdl = (sum(dl_))/len(dl_)\n",
    "    tf_part_val = {}\n",
    "    for term, value in posting_list.items():\n",
    "        for v in value:\n",
    "            tf = v[1]\n",
    "            doc_len = [doc_l for docno,doc_l in dl if docno==v[0]]\n",
    "            bloc_1 = tf*(k+1)\n",
    "            bloc_2 = doc_len[0]/avdl\n",
    "            bloc_3 = k * ((1-b) + b * bloc_2)\n",
    "            bloc_4 = bloc_3+tf       \n",
    "            tf_part_val.setdefault(v[0],[]).append((term,bloc_1/bloc_4)) \n",
    "    return tf_part_val\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71e06e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_part_ = tf_part(pl_2, stat_2['df'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd4321f",
   "metadata": {},
   "outputs": [],
   "source": [
    " def idf_part(posting_list,n):\n",
    "    #log((n-df+0.5)/(df+0.5))\n",
    "    #    [   1    ] [  2   ]\n",
    "    idf_part_val ={}\n",
    "    for term, value in posting_list.items():\n",
    "        df = len(value)\n",
    "        bloc_1 = n-df+0.5\n",
    "        bloc_2 = df + 0.5\n",
    "        \n",
    "        idf_part_val.setdefault(term,[]).append(math.log(bloc_1/bloc_2))\n",
    "        print(idf_part_val)\n",
    "    return idf_part_val\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d6b8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25(posting_list, stat):\n",
    "    tf_part_ = tf_part(posting_list,stat['df'])\n",
    "    print(\"tf get\")\n",
    "    idf_part_ = idf_part(posting_list,stat['n_doc'])\n",
    "    print(\"idf get\") \n",
    "    bm25_val = {}\n",
    "    for term, idf_value in idf_part.items():\n",
    "        for docno,tf_value in tf_part.items():\n",
    "            bm25_val.setdefault(docno,[]).append((tf_value[0], tf_value[1]*idf_value[0]))\n",
    "    \n",
    "    return bm25_val\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90640d60",
   "metadata": {},
   "source": [
    "## Exercise 9: Ranked Retrieval (BM25 weighting) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6005b272",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_val = bm25(pl_2,stat_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa0dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_score= rsv_score(query,bm25_val)\n",
    "score_bm25 = sorted(bm25_score, reverse=True)\n",
    "score_bm25 = [(doc, bm25_) for bm25_, doc in score_bm25]\n",
    "score_bm25[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4b1e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
